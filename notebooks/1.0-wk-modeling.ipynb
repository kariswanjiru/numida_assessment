{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import libraries and data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "import click\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import balanced_accuracy_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_data = '../data/processed/train_loan_data.csv'\n",
    "loan = pd.read_csv(loan_data)\n",
    "loan.head(5).style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loan_data = '../data/processed/test_loan_data.csv'\n",
    "test = pd.read_csv(test_loan_data)\n",
    "test.head(5).style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the column names for both datasets\n",
    "columns_df1 = loan.columns\n",
    "columns_df2 = test.columns\n",
    "\n",
    "# Compare the columns\n",
    "if list(columns_df1) == list(columns_df2):\n",
    "    print(\"The datasets have the same columns.\")\n",
    "else:\n",
    "    print(\"The datasets have different columns.\")\n",
    "    # You can print the specific differences if needed\n",
    "    print(\"Columns in dataset1 but not in dataset2:\", set(columns_df1) - set(columns_df2))\n",
    "    print(\"Columns in dataset2 but not in dataset1:\", set(columns_df2) - set(columns_df1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = loan.drop('approval_status', axis = 1)\n",
    "target = loan['approval_status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features = test.drop('approval_status', axis = 1)\n",
    "test_target = test['approval_status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the random forest classifier\n",
    "rf_model = RandomForestClassifier()\n",
    "rf_model.fit(features, target)\n",
    "prediction = rf_model.predict(test_features)\n",
    "\n",
    "# Measure Metrics\n",
    "print(balanced_accuracy_score(prediction, test_target))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(recall_score(prediction, test_target, average=\"micro\"))\n",
    "\n",
    "model_path = '../models/rf_model.pkl'\n",
    "# Outputting mode\n",
    "pickle.dump(rf_model, open(model_path, \"wb\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complete function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils import get_logger\n",
    "from src.config import MODELS_DIR\n",
    "\n",
    "\n",
    "# logging.\n",
    "logger = get_logger(\"Train Machine Learning Model\")\n",
    "\n",
    "\n",
    "@click.command()\n",
    "@click.argument(\"prepocessed_path\", type=click.Path(exists=True))\n",
    "@click.argument(\"test_preprocessed_path\", type=click.Path(exists=True))\n",
    "def main(\n",
    "    prepocessed_path,\n",
    "    test_preprocessed_path,\n",
    "    model_path: Path = MODELS_DIR / \"rf_model.pkl\",\n",
    "):\n",
    "    logger.info(\"Training some model...\")\n",
    "    loan = pd.read_csv(prepocessed_path)\n",
    "\n",
    "    test = pd.read_csv(test_preprocessed_path)\n",
    "\n",
    "    # Data targets\n",
    "    features = loan.drop(\"approval_status\", axis=1)\n",
    "    target = loan[\"approval_status\"]\n",
    "\n",
    "    # Test target\n",
    "    test_features = test.drop(\"approval_status\", axis=1)\n",
    "    test_target = test[\"approval_status\"]\n",
    "\n",
    "    # Update the random forest classifier\n",
    "    rf_model = RandomForestClassifier()\n",
    "    rf_model.fit(features, target)\n",
    "    prediction = rf_model.predict(test_features)\n",
    "\n",
    "    # Measure Metrics\n",
    "    logger.info(balanced_accuracy_score(prediction, test_target))\n",
    "    logger.info(recall_score(prediction, test_target, average=\"micro\"))\n",
    "\n",
    "    # Outputting model.\n",
    "    pickle.dump(rf_model, open(model_path, \"wb\"))\n",
    "\n",
    "    logger.info(\"Modeling training complete.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "numida",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
